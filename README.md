[![Udacity - Robotics NanoDegree Program](https://s3-us-west-1.amazonaws.com/udacity-robotics/Extra+Images/RoboND_flag.png)](https://www.udacity.com/robotics)

# Map My World 

## Abstract 
The goal of this project is to run the Simultaneous Localization and Mapping (SLAM) algorithm with the custom robot and world created in prior project. To achieve it, the RGB camera in the custom robot needs to be replaced by a RGB-D in order to provide depth information.
We also need to assemble ROS packages to accommodate robots, worlds, and all supporting files including launch scripts. Upon completion, the 2D and 3D maps of the two worlds should be generated by using the RTAB-Map technique.
The ROS package `my_robot` contains the custom robot and custom world built in prior project, `rtabmap` contains the launch files for mapping and localisation and the `teleop_twist_keyboard` package contains the teleop launch file.
The link to the of the Map is stored in `rtab_db.txt` file or find it below.

## Introduction
All prior projects assume that the robot will perform its duties, such as localization, in an environment with a map known to the robot. However, it is not always the case in reality. First of all, it is difficult to acquire an accurate map of a big environment for all applications.
Surveying a big complex environment and make an accurate 2D/3D map can be very expensive, which may not be affordable to most people/companies. On the other hand, most complex environment in real-world changes all the time.
Hence pursuing an accurate and compete map of the entire environment often becomes meaningless. For example, while running a known road, a self-driving car still has to deal with all kinds of moving objects that changes every second, such as pedestrians and other cars. 
As a result, in most cases, the robotic system will have to be able to operate in a dynamic environment, during which SLAM is most likely needed. In this project, the robot will generate 2D and 3D map and localize itself using the RTAB-Map approach both in a custom world previously not known to the robot.
The main goal is the make as fewer passes as possible to generate at least 3 loop closures.

## Background
Multiple algorithms and tools are available today to solve mapping problem. The goal of this project is to solve SLAM problem, and we will mainly focus on Occupancy Grid Mapping, Grid-based FastSLAM, and GraphSLAM algorithms.

### Occupancy Grid Mapping
Unlike SLAM algorithms, the occupancy grid mapping method assumes that the robot pose is known. Its main idea is to represent the world as a uniformly spaced grid, where each cell contains a random variables representing the probability that cell is occupied/obstacle. This nature makes this method suitable for navigation and trajectory planning, which can be difficult to do with SLAM.
SLAM on the other hand assumes that the map is unknown to the robot and simultaneously localizes the robot and maps the world. It is fundamentally much more challenging than Occupancy Grid Mapping. While using SLAM, the accuracy of the map and the localization depend on each other. Hence if one fails to deliver satisfying result the other will also be affected. SLAM takes two forms, online SLAM and full SLAM. Online SLAM estimates the current pose of the robot and map using the present measurements and controls. Full SLAM, or offline SLAM, estimates the robot’s complete trajectory and map using all measurements and control. While both solve for the full SLAM, only one solves the online SLAM problem.

### Grid-based FastSLAM
The basic idea of FastSLAM is to preserve a set of particles to approximate a posterior over the trajectory. It uses low dimensional EKF (Extended Kalman Filter) to solve independent features of the map, which are modeled with a local Gaussian. Because FastSLAM estimates the robot’s full path, this technique solves the full SLAM problem. However, each particle in FastSLAM approximates the robot’s immediate pose, thus this technique also solves the online SLAM problem.
FastSLAM has two types. First type includes FastSLAM 1.0 and 2.0, which are iterative upgrades of the FastSLAM algorithm. The other type is an extension of the FastSLAM algorithm, called Grid-based FastSLAM. The biggest disadvantage of FastSLAM is that it always assumes known landmarks exist on the map, which prevents it from modeling an random environment. This however is not a problem for Grid-based FastSLAM, which keeps the biggest advantage of FastSLAM - using particle filter to solve the localization problem, but extends the algorithm to occupancy grid maps. Grid mapping algorithm can model the environment using grid maps without predefining any landmark hence solves the fundamental issue with FastSLAM.

### GraphSLAM
GraphSLAM addresses the full SLAM problem by estimating the entire path of the robot and the map. Advantages of GraphSLAM include less demanding on onboard processing power and better accuracy than FastSLAM. Since FastSLAM uses randomly generated particles to estimate robot pose, it is possible to find no particle at the most likely position of robot. Due to the limited number of particles, this occurs more often in large environments. GraphSLAM on the other hand can work with all data at once to find the optimal solution. GraphSLAM is also simple to understand. It interprets the data as a set of constraints represented by a graph, and then solves for the optimal estimation of robot path and map while satisfying these constraints.
In this project, RTAB-Map (Real-Time Appearance-Based Mapping), a GraphSLAM method, is used. RTAB-Map utilizes depth camera data to localize the robot and map the environment in real time. It also uses the so called loop closure method to determine a robot has seen a location before and therefore enhance the accuracy of the map. RTAB-Map is good for large-scale and long-term SLAM by using multiple strategies to allow loop closure to be done in real-time

## Robot Setup
The custom robot has a cuboid-shape chassis with a Laser Scanner on top. The Camera is mounted on front of the cylinder chassis. It has two wheels in the middle section of the chassis and two casters - one in front and one in the back, to maintain balance. 
In this project, the RGB camera is replaced by a RGB-D camera, which provides depth information to RTAB-Map algorithm to help conduct SLAM.

Robot specs and screenshot are given below.

| Component          | Shape    | Size             |
|:------------------:|:--------:|:----------------:|
| chassis            | Cuboid   | L=0.4 B=0.2 H=0.1|
| dome               | Sphere   | R=0.1            |
| wheel              | Cylinder | R=0.05 L=0.1     |
| caster             | Sphere   | R=0.05           |

![](https://github.com/Ekanshh/rse_p5_udacity/blob/master/Images/my_robot.png)

## Virtual World Setup
This project requires the robot to SLAM in a custom virtual world.
The custom environment is built upon the `office` model that comes with `Gazebo`. Some small to mid sized objects are added, such as Tables,boxes, custom manipulator model, humans, etc., to create more features for robot to capture during mapping.
A screenshot is given below.

![](https://github.com/Ekanshh/rse_p5_udacity/blob/master/Images/my_world.png)

## Results
Due to GitHub file size limitation, map database is stored on Google drive:
- Custom World: [https://drive.google.com/open?id=1vHGxwUqMJK-WpbB8oHgOpej0Y5n8AEqI](https://drive.google.com/open?id=1vHGxwUqMJK-WpbB8oHgOpej0Y5n8AEqI)

| 2D Map                                                                       | 3D Map                                          |
:-----------------------------------------------------------------------------:|:-----------------------------------------------:
![](https://github.com/Ekanshh/rse_p5_udacity/blob/master/Images/2D_map.png)   | ![](https://github.com/Ekanshh/rse_p5_udacity/blob/master/Images/3D_view.png)

As in above picture, a total of 6 global loop closures were detected during SLAM.

## Discussion
In general, mapping the virtual world was successful.It occurred to me that rotating the robot in place would cause the mapping node to continuously throw warnings about insufficient inliers and disrupt the generated 3D map. It was possibly due to robot not having liner speed and RTAB-Map was confused. Minimizing rotating movements (J and L key in teleop) seemed to solve the problem.
Another lesson learned was that the mount position and angle of the depth camera could also affect SLAM performance. The depth camera on my custom robot is mounted to a relatively low position hence cannot see tall objects if too close. It affected the mapping speed. Solution was to not travel too close to tall feature rich objects so as to catch more features in fewer passes.

## Future Work
I would like try a different robot design with camera mounted a little higher. The virtual world could also be easier to map if more features or objects can be added. The default selections of objects in `Gazebo` are quite limited for building a complex virtual world. I will try getting more models from other custom worlds available online.

## How to use

1. Clone repo to `/home/workspace/src`. Then, compile the code:
```
cd /home/workspace/
catkin_make
```

2. Open three individual terminal and launch the files:

`roslaunch my_robot world.launch`

`roslaunch teleop_twist_keyboard teleop.launch`

`roslaunch rtabmap mapping.launch`

3. In Rviz: 
Add `Robot Model`.
Add `Map` and select the topic `/map`

Note: To stop mapping, we have to hit `ctrl+c` to terminate the mapping node, which upon shutting down will print that map has been saved to hard drive. 
Simply closing the mapping node terminal window will not save the map, hence `rtabmap-databaseViewer` will also show an empty map.

----------
_Readme Source: [Heming Chen](https://github.com/hemingchen)_
